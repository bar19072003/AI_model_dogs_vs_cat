# üê∂ Dogs vs. Cats ‚Äî CNN Classifier & FastAPI Inference

A simple, production-ready pipeline to train a CNN that classifies dog/cat images and to serve predictions via a FastAPI endpoint and a minimal web UI.

---

## Features

- TensorFlow/Keras CNN trained from scratch (BatchNorm + Dropout).
- Automatic best nodel saving via `ModelCheckpoint` (`best_model.keras`).
- FASTAPI server for inference: `/predict` (multipart image upload).
- Lightweight web UI (HTML/CSS/JS) for drag-and-drop image testing.
- Reproducible training with `train/val` split and data cleaning.

---

## Project Structure

Dogs-vs-cats-AI-model/
‚îú‚îÄ app.py                  # FastAPI app with / and /predict
‚îú‚îÄ model.py                # Data prep + training script
‚îú‚îÄ best_model.keras        # Saved best model (created after training)
‚îú‚îÄ requirements.txt        # Python dependencies
‚îú‚îÄ index.html              # Minimal web interface
‚îî‚îÄ static/
‚îú‚îÄ style.css
‚îî‚îÄ app.js

The dataset is expected under `PetImages/` with subfolders `Cat/` and `Dog/` (Kaggle ‚ÄúCat and Dog‚Äù style). Adjust paths in `model.py` if needed.

---

## Getting Started

### 1) Environment 

```bash
python3 -m venv .venv
source .venv/bin/activate          # Windows: .venv\Scripts\activate
pip install -r requirements.txt

### 2) Train the Model

```bash
python model.py

what is does:
    ‚Ä¢	Scans PetImages/, removes corrupt files, builds a dataframe.
	‚Ä¢	Splits into train/validation using train_test_split.
	‚Ä¢	Trains a small CNN with BatchNormalization and Dropout.
	‚Ä¢	Saves the best checkpoint to best_model.keras (monitors val_loss).
	‚Ä¢	Prints learning curves and best validation accuracy.

### 3) Run the API Server

```bash
uvicorn app:app --host 0.0.0.0 --port 8000 --reload

open:
    ‚Ä¢	Web UI: http://localhost:8000 (upload an image and see the prediction)
	‚Ä¢	Interactive docs: http://localhost:8000/docs 


## API

POST / predict:
    ‚Ä¢	Body: multipart/form-data with field file (image: png/jpg/jpeg).
	‚Ä¢	Response:
        ```json
        {
        "label": "cat",
        "confidence": 0.9823
        }


## Model Details

‚Ä¢	Input size: 128√ó128 RGB.
‚Ä¢	Backbone: 4√ó Conv2D blocks (16‚Üí128 filters), each with BN + MaxPool.
‚Ä¢	Head: Flatten ‚Üí Dense(512, relu) + BN + Dropout(0.4) ‚Üí Dense(1, sigmoid).
‚Ä¢	Optimizer: Adam (lr=3e-4, clipnorm=1.0).
‚Ä¢	Callbacks: ModelCheckpoint(save_best_only=True), ReduceLROnPlateau, EarlyStopping(restore_best_weights=True).


## Results (example)

- Train accuracy: ~93%
- Validation accuracy: ~90%
- Improvement: +4% after adding BatchNorm & Dropout

> Your exact numbers may vary depending on dataset cleaning, augmentations, and random seed.

---

## Configuration

Key knobs (edit in `model.py`):
- Data Augmentation: rotation/zoom/shear/flip in `ImageDataGenerator`.
- Batch size: default `64`.
- Epochs: default `15` with early stopping.
- Learning rate schedule: `ReduceLROnPlateau` halves LR on plateaus.

---

## Reproducibility

- Fixed `random_state=42` for splits.
- Set `shuffle=False` on validation iterator for deterministic evaluation.
- For strict reproducibility, also set global seeds for NumPy/TensorFlow and disable nondeterministic ops.

---

## Troubleshooting

- `OSError: cannot identify image file`**  
  Corrupted images ‚Äî this repo verifies and filters them before training.

- Different results across runs
  Expected with stochastic optimizers. Use seeds and keep `val_iterator` deterministic.

- `best_model.keras` not created  
  Ensure `ModelCheckpoint(save_best_only=True, monitor='val_loss')` is active and you ran `model.py` to completion.

---

## Roadmap

- Add proper test split (train/val/test).
- Export to TensorFlow Lite for mobile.
- Add Grad-CAM visualization for interpretability.

---

## Contributing

PRs and issues are welcome. Please format code with `black` / `ruff` and include a brief description of changes and validation steps.

---

## Acknowledgements

- Dataset layout compatible with Kaggle ‚ÄúCats and Dogs‚Äù.
- Built with TensorFlow/Keras and FastAPI.